{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a976365-274f-4164-9126-94115bb7e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4341db1-94ba-403b-bd1c-a48957f0a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torchtext\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8758a6-428a-418c-b549-2d7eff1e4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54dc0e-3826-46e3-97dc-20e1b2f0bbd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ffb1d-da5c-4d3b-9452-7c7550b9d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import spacy.cli\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "# spacy.cli.download(\"fr_core_news_sm\")\n",
    "\n",
    "import fr_core_news_sm\n",
    "import en_core_web_sm\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "spacy_fr = fr_core_news_sm.load()\n",
    "spacy_en = en_core_web_sm.load()\n",
    "\n",
    "spacy_en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "spacy_fr_tokenizer = get_tokenizer(\"spacy\", language=\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3488b-00f4-411b-b9f1-b7327373849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, Counter\n",
    "from torchtext.vocab import vocab\n",
    "import io\n",
    "\n",
    "path = './data/eng-fre/'\n",
    "train_fn = 'train_eng_fre.tsv'\n",
    "valid_fn = 'val_eng_fre.tsv'\n",
    "test_fn = 'test_eng_fre.tsv'\n",
    "\n",
    "\n",
    "def build_vocab(filepath, src_tokenizer, trg_tokenizer):\n",
    "  \"\"\"Generate vocabulary objects for source and target languages.\"\"\"\n",
    "  src_counter, trg_counter = Counter(), Counter()\n",
    "  with open(filepath, encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "      if i == 0:  # skip header\n",
    "        continue\n",
    "      # split line and tokenize accordingly\n",
    "      trg_line, src_line = line.strip(\"\\n\").split(\"\\t\")\n",
    "      src_counter.update(src_tokenizer(src_line.lower()))\n",
    "      trg_counter.update(trg_tokenizer(trg_line.lower()))\n",
    "    \n",
    "    # sort and wrap as OrderedDict\n",
    "    ordered_src = OrderedDict(sorted(src_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "    ordered_trg = OrderedDict(sorted(trg_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    # build src and trg vocab objects\n",
    "    src_vocab = vocab(\n",
    "      ordered_src, \n",
    "      min_freq=2, \n",
    "      specials=('<unk>', '<pad>', '<bos>', '<eos>')\n",
    "    )\n",
    "\n",
    "    trg_vocab = vocab(\n",
    "      ordered_trg, \n",
    "      min_freq=2,\n",
    "      specials=('<unk>', '<pad>', '<bos>', '<eos>')\n",
    "    )\n",
    "    \n",
    "    return src_vocab, trg_vocab\n",
    "\n",
    "src_vocab, trg_vocab = build_vocab(\n",
    "  path + train_fn, \n",
    "  spacy_fr_tokenizer,\n",
    "  spacy_en_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa806231-77a9-4ffa-8ffd-ca73740fa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open(\"./ckpt/src_vocab\",\"rb\") as f: \n",
    "#      src_vocab = pickle.load(f)\n",
    "# with open(\"./ckpt/trg_vocab\",\"rb\") as f:\n",
    "#      trg_vocab = pickle.load(f)\n",
    "\n",
    "with open(\"./ckpt/src_vocab\", \"wb\") as f:\n",
    "     pickle.dump(src_vocab, f)\n",
    "\n",
    "with open(\"./ckpt/trg_vocab\", \"wb\") as f:\n",
    "     pickle.dump(trg_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172987f-b6a7-4a51-8f6f-cf762eb0db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch size for each split\n",
    "BATCH_SIZE = {\n",
    "  \"train\": 16,\n",
    "  \"val\": 256,\n",
    "  \"test\": 256\n",
    "}\n",
    "\n",
    "# Extract idx for special tokens required for tensor batching\n",
    "PAD_IDX = trg_vocab['<pad>']\n",
    "BOS_IDX = trg_vocab['<bos>']\n",
    "EOS_IDX = trg_vocab['<eos>']\n",
    "\n",
    "# Define default index to assign to OOV tokens\n",
    "unk_token = '<unk>'\n",
    "src_vocab.set_default_index(src_vocab[unk_token])\n",
    "trg_vocab.set_default_index(trg_vocab[unk_token])\n",
    "\n",
    "\n",
    "def data_process(path, split):\n",
    "  \"\"\"Convert raw source and target sentences into tensors.\"\"\"\n",
    "  raw_iter = iter(io.open(path + split, encoding=\"utf-8\"))\n",
    "  data = []\n",
    "  for i, item in enumerate(raw_iter):\n",
    "    if i == 0:\n",
    "      continue\n",
    "    trg_raw, src_raw = item.strip(\"\\n\").split(\"\\t\")\n",
    "    src_tensor = torch.tensor(\n",
    "        [src_vocab[token] for token in spacy_fr_tokenizer(src_raw.lower())],\n",
    "        dtype=torch.long\n",
    "      )\n",
    "    trg_tensor = torch.tensor(\n",
    "        [trg_vocab[token] for token in spacy_en_tokenizer(trg_raw.lower())],\n",
    "        dtype=torch.long\n",
    "      )\n",
    "    data.append((src_tensor, trg_tensor))\n",
    "\n",
    "  return data\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "  \"\"\"Take a batch of tensors and turn them into fixed-sized tensors.\"\"\"\n",
    "  src_batch, trg_batch = [], []\n",
    "  for (src_item, trg_item) in data_batch:\n",
    "    src_batch.append(torch.cat([torch.tensor([BOS_IDX]), src_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    trg_batch.append(torch.cat([torch.tensor([BOS_IDX]), trg_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "  trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "\n",
    "  return src_batch, trg_batch\n",
    "\n",
    "train_data = data_process(path, train_fn)\n",
    "val_data = data_process(path, valid_fn)\n",
    "test_data = data_process(path, test_fn)\n",
    "\n",
    "train_iter = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=BATCH_SIZE[\"train\"],\n",
    "    shuffle=True, \n",
    "    collate_fn=generate_batch\n",
    ")\n",
    "\n",
    "valid_iter = DataLoader(\n",
    "    val_data, \n",
    "    batch_size=BATCH_SIZE[\"val\"],\n",
    "    shuffle=True, \n",
    "    collate_fn=generate_batch\n",
    "  )\n",
    "\n",
    "test_iter = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=BATCH_SIZE[\"test\"],\n",
    "    shuffle=True, \n",
    "    collate_fn=generate_batch\n",
    "  )\n",
    "\n",
    "\n",
    "with open(\"./ckpt/train_iter\", \"wb\") as f:\n",
    "     pickle.dump(train_iter, f)\n",
    "\n",
    "with open(\"./ckpt/valid_iter\", \"wb\") as f:\n",
    "     pickle.dump(valid_iter, f)\n",
    "\n",
    "with open(\"./ckpt/test_iter\", \"wb\") as f:\n",
    "     pickle.dump(test_iter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffa754-6139-4b91-9aaf-cc47c50b7f32",
   "metadata": {},
   "source": [
    "## load iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65e5d4-ab7e-4ece-89c9-81e468b149f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"./drive/My Drive/COLX_531_lab2_jxkuang/ckpt/train_iter\", \"rb\") as f:\n",
    "#     train_iter = pickle.load(f)\n",
    "\n",
    "# with open(\"./drive/My Drive/COLX_531_lab2_jxkuang/ckpt/valid_iter\", \"rb\") as f:\n",
    "#     valid_iter = pickle.load(f)\n",
    "\n",
    "# with open(\"./drive/My Drive/COLX_531_lab2_jxkuang/ckpt/test_iter\", \"rb\") as f:\n",
    "#     test_iter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a52a9-590f-4f04-8819-01d1e6f6b596",
   "metadata": {},
   "source": [
    "# Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8412003-5e37-4c4a-8627-408ee4a60a68",
   "metadata": {},
   "source": [
    "## Notes: models from Seq2Seq_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad22fdb-94ba-40dc-9840-3e145c2f837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(trg_vocab)\n",
    "\n",
    "# hyperparameters\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512  # NOTE: enc_hid_dim and dec_hid_dim should be equal\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_LAYERS = 1\n",
    "LEARNING_RT = 0.001\n",
    "BIDIRECTIONAL = True ### your code here ###\n",
    "\n",
    "# model components\n",
    "#device = \"cpu\"  # for more precise debugging\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL) #<--------------\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "model_n = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# # model\n",
    "# enc = Encoder1(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "# dec = Decoder1(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "# model1 = Seq2Seq1(enc, dec, device).to(device)\n",
    "\n",
    "# # model2 components\n",
    "# attn = Attention2(ENC_HID_DIM, DEC_HID_DIM)\n",
    "# enc = Encoder2(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "# dec = Decoder2(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "# model2 = Seq2Seq2(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d339a-db70-4255-a37e-af16b6eceb8b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50646ce8-5303-41a0-851c-9d8dadeb66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_n #################################### change\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RT)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e9c90-6d04-4f2e-8b92-aa48d14aa1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training procedure goes here as needed. (can use the tutorial as a guide)\n",
    "# BE SURE TO USE THE SAME SEED EACH TIME YOU RUN!\n",
    "manual_seed = 531\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        if i % 500 == 0:\n",
    "          print(i)\n",
    "        i+=1\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(src, trg)\n",
    "        output,_ = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            # output = model(src, trg, 0)\n",
    "            output,_ = model(src, trg, 0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # Create checkpoint at end of each epoch\n",
    "    state_dict_model = model.state_dict() \n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state_dict_model,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "    torch.save(state, \"./ckpt/seq2seq_\"+str(epoch+1)+\".pt\")\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910004c-31e8-45fa-bcde-b5a52bfb27ca",
   "metadata": {},
   "source": [
    "# Evaluation of the model using BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee81e60-c8e1-4682-8b99-d48a42b05d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./ckpt/src_vocab\",\"rb\") as f:\n",
    "     src_saved = pickle.load(f)\n",
    "\n",
    "with open(\"./ckpt/trg_vocab\",\"rb\") as f:\n",
    "     trg_saved = pickle.load(f)\n",
    "\n",
    "# with open(\"./ckpt/test_iter\", \"rb\") as f:\n",
    "#     test_iter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617099d3-0097-4c84-a8b2-37a3f32d1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(trg_vocab)\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_LAYERS = 1\n",
    "LEARNING_RT = 0.001\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "# model components\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "model_best = Seq2Seq(enc, dec, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9574888-e309-40a1-b825-a51c8de1b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.load_state_dict(torch.load('./ckpt/seq2seq_5.pt')['state_dict']) # choose the best\n",
    "model_best = model_best.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1ebac-1f7d-4302-89cc-16aad29a9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_inference(model, trg_vocab, test_iter, attention=False, max_trg_len=64):\n",
    "    '''\n",
    "    Function for translation inference\n",
    "\n",
    "    Input: \n",
    "    model: translation model;\n",
    "    trg_vocab: Target torchtext Vocab.\n",
    "    test_iter: iterator object with test data.\n",
    "    attention: the model returns attention weights or not.\n",
    "    max_trg_len: the maximal length of translation text (optinal), default = 64\n",
    "\n",
    "    Output:\n",
    "    Corpus BLEU score.\n",
    "    '''\n",
    "    from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "    # initializes smoothing function\n",
    "    chencherry = SmoothingFunction()\n",
    "\n",
    "    # convert index to text string\n",
    "    def convert_itos(convert_vocab, token_ids):\n",
    "        list_string = []\n",
    "        for i in token_ids:\n",
    "            if i == convert_vocab.get_stoi()['<eos>']:\n",
    "                break\n",
    "            else:\n",
    "                token = convert_vocab.get_itos()[i]\n",
    "                list_string.append(token)\n",
    "        return list_string\n",
    "\n",
    "    model.eval()\n",
    "    all_trg = []\n",
    "    all_translated_trg = []\n",
    "\n",
    "    TRG_PAD_IDX = trg_vocab['<pad>']\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, (src, trg) in enumerate(test_iter):\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            batch_size = trg.shape[1]\n",
    "\n",
    "            # create a placeholder for target language with shape of [max_trg_len, batch_size] where all the elements are the index of <pad>. Then send to device\n",
    "            trg_placeholder = torch.Tensor(max_trg_len, batch_size)\n",
    "            trg_placeholder.fill_(TRG_PAD_IDX)\n",
    "            trg_placeholder = trg_placeholder.long().to(device)\n",
    "            if attention == True:\n",
    "                output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
    "            else:\n",
    "                #original \n",
    "                #output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
    "                \n",
    "                # update:\n",
    "                output = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
    "            # get translation results, we ignor first token <sos> in both translation and target sentences. \n",
    "            # output_translate = [(trg len - 1), batch, output dim] output dim is size of target vocabulary.\n",
    "            output_translate = output[1:]\n",
    "            # store gold target sentences to a list \n",
    "            all_trg.append(trg[1:].cpu())\n",
    "\n",
    "            # Choose top 1 word from decoder's output, we get the probability and index of the word\n",
    "            prob, token_id = output_translate.data.topk(1)\n",
    "            translation_token_id = token_id.squeeze(2).cpu()\n",
    "\n",
    "            # store gold target sentences to a list \n",
    "            all_translated_trg.append(translation_token_id)\n",
    "      \n",
    "    all_gold_text = []\n",
    "    all_translated_text = []\n",
    "    for i in range(len(all_trg)): \n",
    "        cur_gold = all_trg[i]\n",
    "        cur_translation = all_translated_trg[i]\n",
    "        for j in range(cur_gold.shape[1]):\n",
    "            gold_convered_strings = convert_itos(trg_vocab, cur_gold[:, j])\n",
    "            trans_convered_strings = convert_itos(trg_vocab, cur_translation[:, j])\n",
    "\n",
    "            all_gold_text.append(gold_convered_strings)\n",
    "            all_translated_text.append(trans_convered_strings)\n",
    "\n",
    "    corpus_all_gold_text = [[item] for item in all_gold_text]\n",
    "    # compute bleu with smoothing function (chencherry method 0)\n",
    "    # see: https://www.nltk.org/api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction\n",
    "    corpus_bleu_score = corpus_bleu(corpus_all_gold_text, all_translated_text, smoothing_function=chencherry.method0)  \n",
    "    return corpus_bleu_score\n",
    "\n",
    "# NOTE: Don't forget to run the below line to get the results you need, passing in 'model' with the proper weight initiatlization\n",
    "# print(new_inference(model, trg_vocab, test_iter, attention=False, max_trg_len=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6bb3b-9fed-4aff-86eb-07fd2b6ade16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_inference(model_best, trg_saved, test_iter, attention=True, max_trg_len=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17601c25-11c4-4164-9fe7-eaf387f38b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09e295-00f2-430c-9971-7e519b902cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770a977-7103-4fef-9a15-8afdf3f9e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407616c-069e-46f9-8aea-7da8fd706533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
